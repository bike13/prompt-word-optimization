from fastapi import APIRouter, HTTPException, Body
from pydantic import BaseModel
from typing import List, Optional
import openai
import os
from dotenv import load_dotenv
import time

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥prompt_html.pyä¸­çš„æç¤ºè¯
from prompt_html import prompt_list, get_fix_prompt, get_modelfix_prompt

# å¯¼å…¥æ—¥å¿—å·¥å…·
from utils.logger_utils import logger, log_api_call

router = APIRouter()


# HTMLä¿®å¤æ¥å£
# è¯·æ±‚å‚æ•°ï¼šhtml_content + template_content(å¯é€‰)
# è¯·æ±‚æ–¹å¼ï¼šPOST
# è¿”å›å‚æ•°ï¼šfixed_html
# ä½¿ç”¨ prompt_list["prompt_fix"] è·å–ç³»ç»Ÿæç¤ºè¯ï¼Œ html_content å’Œ template_content ä½œä¸ºæ¶ˆæ¯ è¯·æ±‚å¤§æ¨¡å‹ è·å–ç»“æœ
@router.post("/html_fix")
@log_api_call("/html_fix", "POST")
async def html_fix(request: dict = Body(...)):
    try:
        # è®°å½•ä¸šåŠ¡é€»è¾‘å¼€å§‹
        logger.business_logic("html_fix", "å¼€å§‹å¤„ç†HTMLä¿®å¤è¯·æ±‚")
        
        # æå–è¯·æ±‚å‚æ•°
        html_content = request.get("html_content", "")
        template_content = request.get("template_content", "")
        
        # è®°å½•å‚æ•°ä¿¡æ¯
        logger.parameters(
            (f"html_contenté•¿åº¦: {len(html_content)}", "Integer"),
            (f"template_contenté•¿åº¦: {len(template_content)}", "Integer")
        )
        
        if not html_content:
            logger.error("html_fix", "html_content å‚æ•°ä¸ºç©º")
            raise HTTPException(status_code=400, detail="html_content å‚æ•°ä¸èƒ½ä¸ºç©º")
        
        # è·å–ç³»ç»Ÿæç¤ºè¯
        logger.business_logic("html_fix", "è·å–ç³»ç»Ÿæç¤ºè¯")
        system_prompt = prompt_list["prompt_fix"]
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = f"éœ€è¦ä¿®å¤çš„HTMLä»£ç ï¼š\n```html\n{html_content}\n```"
        
        # å¦‚æœæä¾›äº†æ¨¡æ¿å†…å®¹ï¼Œæ·»åŠ åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­
        if template_content:
            user_message += f"\n\nå‚è€ƒæ¨¡æ¿/æ¡ˆä¾‹é¡µé¢ï¼š\n```html\n{template_content}\n```"
        
        # è°ƒç”¨OpenAI API
        logger.business_logic("html_fix", "åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯")
        client = openai.OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_API_BASE")
        )
        
        # è®°å½•æ¨¡å‹æ¨ç†å¼€å§‹
        model_name = os.getenv("LITE_TEXT_API_MODEL")
        logger.model_inference(model_name, input_tokens=len(user_message) + len(system_prompt))
        
        start_time = time.time()
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.3,
            max_tokens=12000
        )
        response_time = time.time() - start_time
        
        fixed_html = response.choices[0].message.content
        
        # è®°å½•æ¨¡å‹æ¨ç†ç»“æœ
        logger.model_inference(
            model_name, 
            input_tokens=len(user_message) + len(system_prompt),
            output_tokens=len(fixed_html) if fixed_html else 0,
            response_time=response_time
        )
        
        # è®°å½•ä¿®å¤ç»“æœä¿¡æ¯
        logger.info(f"HTMLä¿®å¤å®Œæˆ - ç»“æœé•¿åº¦: {len(fixed_html) if fixed_html else 0}")
        logger.debug(f"ä¿®å¤ç»“æœé¢„è§ˆ: {fixed_html[:200] if fixed_html else 'None'}...")
        
        # è®°å½•æˆåŠŸå®Œæˆ
        logger.business_logic("html_fix", "HTMLä¿®å¤è¯·æ±‚å¤„ç†å®Œæˆ")
        
        return {
            "success": True,
            "fixed_html": fixed_html,
            "message": "HTMLä¿®å¤å®Œæˆ"
        }
        
    except Exception as e:
        # è®°å½•é”™è¯¯ä¿¡æ¯
        logger.error(f"html_fix å¤„ç†å¤±è´¥: {str(e)}")
        logger.api_error("/html_fix", "POST", str(e), type(e).__name__)
        raise HTTPException(status_code=500, detail=f"HTMLä¿®å¤å¤±è´¥: {str(e)}")


# HTMLæ¨¡æ¿ä¿®å¤æ¥å£
# è¯·æ±‚å‚æ•°ï¼šhtml_content + template_content + fix_mode
# è¯·æ±‚æ–¹å¼ï¼šPOST
# è¿”å›å‚æ•°ï¼šfixed_html
# ä½¿ç”¨ get_modelfix_prompt() è·å–ç³»ç»Ÿæç¤ºè¯ï¼Œä¸¥æ ¼æŒ‰ç…§æ¨¡æ¿æ ¼å¼è¿›è¡Œä¿®å¤
@router.post("/html_template_fix")
@log_api_call("/html_template_fix", "POST")
async def html_template_fix(request: dict = Body(...)):
    try:
        # è®°å½•ä¸šåŠ¡é€»è¾‘å¼€å§‹
        logger.business_logic("html_template_fix", "å¼€å§‹å¤„ç†HTMLæ¨¡æ¿ä¿®å¤è¯·æ±‚")
        
        # æå–è¯·æ±‚å‚æ•°
        html_content = request.get("html_content", "")
        template_content = request.get("template_content", "")
        fix_mode = request.get("fix_mode", "strict")  # strict: ä¸¥æ ¼æ¨¡å¼, flexible: çµæ´»æ¨¡å¼
        
        # è®°å½•å‚æ•°ä¿¡æ¯
        logger.parameters(
            (f"html_contenté•¿åº¦: {len(html_content)}", "Integer"),
            (f"template_contenté•¿åº¦: {len(template_content)}", "Integer"),
            (f"fix_mode: {fix_mode}", "String")
        )
        
        if not html_content:
            logger.error("html_template_fix", "html_content å‚æ•°ä¸ºç©º")
            raise HTTPException(status_code=400, detail="html_content å‚æ•°ä¸èƒ½ä¸ºç©º")
        
        if not template_content:
            logger.error("html_template_fix", "template_content å‚æ•°ä¸ºç©º")
            raise HTTPException(status_code=400, detail="template_content å‚æ•°ä¸èƒ½ä¸ºç©º")
        
        # æ„å»ºå¯¹è¯æ–‡æœ¬ï¼ŒåŒ…å«æ¨¡æ¿å†…å®¹
        conversation_text = f"""
## ğŸ“‹ ç”¨æˆ·æä¾›çš„æ¨¡æ¿å†…å®¹ï¼š
```html
{template_content}
```

## ğŸ”§ éœ€è¦ä¿®å¤çš„HTMLä»£ç ï¼š
```html
{html_content}
```

## ğŸ¯ ä¿®å¤è¦æ±‚ï¼š
- ä¿®å¤æ¨¡å¼ï¼š{fix_mode}
- ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ¨¡æ¿æ ¼å¼è¿›è¡Œä¿®å¤
- ç¡®ä¿ä¿®å¤åçš„HTMLç»“æ„ä¸æ¨¡æ¿100%ä¸€è‡´
- ä¿æŒåŸå§‹å†…å®¹å®Œæ•´æ€§ï¼Œä»…è°ƒæ•´ç»“æ„ä»¥åŒ¹é…æ¨¡æ¿
"""
        
        # è·å–ç³»ç»Ÿæç¤ºè¯
        logger.business_logic("html_template_fix", "è·å–æ¨¡æ¿ä¿®å¤æç¤ºè¯")
        system_prompt = get_modelfix_prompt(conversation_text)
        
        # è°ƒç”¨OpenAI API
        logger.business_logic("html_template_fix", "åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯")
        client = openai.OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
        )
        
        # è®°å½•æ¨¡å‹æ¨ç†å¼€å§‹
        model_name = os.getenv("LITE_TEXT_API_MODEL", "gpt-4o")
        logger.model_inference(model_name, input_tokens=len(conversation_text) + len(system_prompt))
        
        start_time = time.time()
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": "è¯·ä¸¥æ ¼æŒ‰ç…§æä¾›çš„æ¨¡æ¿æ ¼å¼ä¿®å¤HTMLä»£ç "}
            ],
            temperature=0.1,  # ä½¿ç”¨æ›´ä½çš„æ¸©åº¦ç¡®ä¿ä¸¥æ ¼æŒ‰ç…§æ¨¡æ¿æ‰§è¡Œ
            max_tokens=12000
        )
        response_time = time.time() - start_time
        
        fixed_html = response.choices[0].message.content
        
        # è®°å½•æ¨¡å‹æ¨ç†ç»“æœ
        logger.model_inference(
            model_name, 
            input_tokens=len(conversation_text) + len(system_prompt),
            output_tokens=len(fixed_html) if fixed_html else 0,
            response_time=response_time
        )
        
        # è®°å½•ä¿®å¤ç»“æœä¿¡æ¯
        logger.info(f"HTMLæ¨¡æ¿ä¿®å¤å®Œæˆ - ç»“æœé•¿åº¦: {len(fixed_html) if fixed_html else 0}")
        logger.debug(f"ä¿®å¤ç»“æœé¢„è§ˆ: {fixed_html[:200] if fixed_html else 'None'}...")
        
        # è®°å½•æˆåŠŸå®Œæˆ
        logger.business_logic("html_template_fix", "HTMLæ¨¡æ¿ä¿®å¤è¯·æ±‚å¤„ç†å®Œæˆ")
        
        return {
            "success": True,
            "fixed_html": fixed_html,
            "fix_mode": fix_mode,
            "message": "HTMLæ¨¡æ¿ä¿®å¤å®Œæˆ"
        }
        
    except Exception as e:
        # è®°å½•é”™è¯¯ä¿¡æ¯
        logger.error(f"html_template_fix å¤„ç†å¤±è´¥: {str(e)}")
        logger.api_error("/html_template_fix", "POST", str(e), type(e).__name__)
        raise HTTPException(status_code=500, detail=f"HTMLæ¨¡æ¿ä¿®å¤å¤±è´¥: {str(e)}")

